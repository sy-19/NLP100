{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "tdAw3goJ3yk4",
    "outputId": "92541783-684c-4fb6-8122-9af471b8795c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 11772456075004223523, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 6622977668144984277\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 9111546300505245226\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11146722048\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2506712392756921354\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLruIHLY37Pr"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "KfThqkau4bqs",
    "outputId": "a6e388ff-9988-41e6-ff80-639ab2df37d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3574855938552438357, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 9572691709295741068\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dC0LFYDg4gQO",
    "outputId": "1eda9e99-24fc-4e9d-d887-ee8857204058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "str = \"stressed\"\n",
    "str_r = list(reversed(str))\n",
    "print(''.join(str_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wlbjLXKk5Z8U",
    "outputId": "4b535976-cb4e-4ffa-ce6a-5fb681125137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトかー\n"
     ]
    }
   ],
   "source": [
    "str = \"パタトクかシー\"\n",
    "str_odd = [a for idx,a in enumerate(list(str)) if idx%2 == 0]\n",
    "print(''.join(str_odd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4l-b58dF6Hs0",
    "outputId": "730cd090-1647-4afb-a812-9c333c757cb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "str = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "str_word_list = str.split(' ')\n",
    "str_count_list = [len(list(regex.sub('',a))) for a in str_word_list]\n",
    "print(str_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "xmqkAM5T86Sf",
    "outputId": "d01941b5-3526-4dae-ae4c-00e83d24151a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'H', 2: 'He', 3: 'Li', 4: 'Be', 5: 'B', 6: 'C', 7: 'N', 8: 'O', 9: 'F', 10: 'Ne', 11: 'Na', 12: 'Mi', 13: 'Al', 14: 'Si', 15: 'P', 16: 'S', 17: 'Cl', 18: 'Ar', 19: 'K', 20: 'Ca'}\n"
     ]
    }
   ],
   "source": [
    "str = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "num_list = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "str_word_list = str.split(' ')\n",
    "word_dict = {}\n",
    "for idx,word in enumerate(str_word_list):\n",
    "  num = idx+1\n",
    "  if num in num_list:\n",
    "    word_dict[num] = list(word)[0]\n",
    "  else:\n",
    "    word_dict[num] = ''.join(list(word)[0:2])\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OLSf-TjU6lWw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "def n_gram(target, n):\n",
    "    # 基準を１文字（単語）ずつずらしながらn文字分抜き出す\n",
    "    return [target[idx:idx + n]for idx in range(len(target)-n+1)]\n",
    "\n",
    "target = \"I am an NLPer\"\n",
    "# 単語bi-gram\n",
    "print(n_gram(target.split(' '),2))\n",
    "# 文字bi-gram\n",
    "print(n_gram(target,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'se', 'pa', 'ap', 'ar', 'ad', 'gr', 'ra', 'ag', 'is', 'di', 'ph'}\n",
      "{'pa', 'ar', 'ap', 'ra'}\n",
      "{'se', 'is', 'di', 'ad'}\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "X_target = \"paraparaparadise\"\n",
    "Y_target = \"paragraph\"\n",
    "X = n_gram(X_target,2)\n",
    "Y = n_gram(Y_target,2)\n",
    "# 和集合\n",
    "print(set(X).union(set(Y)))\n",
    "# 積集合\n",
    "print(set(X).intersection(set(Y)))\n",
    "# 差集合\n",
    "print(set(X).difference(set(Y)))\n",
    "# 'se'が含まれるか\n",
    "print(\"se\" in X)\n",
    "print(\"se\" in Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def template(x,y,z):\n",
    "    return (str(x)+\"時の\"+str(y)+\"は\"+str(z))\n",
    "\n",
    "print(template(12,\"気温\",22.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平文 The quick brown fox jumps over the lazy dog. 1234567890\n",
      "暗号文 Tsv jfrxp yildm ulc qfnkh levi gsv ozab wlt. 1234567890\n",
      "復号文 The quick brown fox jumps over the lazy dog. 1234567890\n"
     ]
    }
   ],
   "source": [
    "def cipher(message):\n",
    "    return_message = [chr(219 - ord(x)) if x.islower() else x for x in message]\n",
    "    return ''.join(return_message)\n",
    "original_message = 'The quick brown fox jumps over the lazy dog. 1234567890'\n",
    "print('平文', original_message)\n",
    "encode_message = cipher(original_message)\n",
    "print('暗号文',encode_message)\n",
    "decode_message = cipher(encode_message)\n",
    "print('復号文',decode_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'cnod’ult', 'bveliee', 'that', 'I', 'cuold', 'alculaty', 'uasnerndtd', 'what', 'I', 'was', 'redanig', ':', 'the', 'pehnnomael', 'pewor', 'of', 'the', 'huamn', 'mind', '.']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def shuffle_str(word):\n",
    "    x = list(word)\n",
    "    random.shuffle(x)\n",
    "    return ''.join(x)\n",
    "    \n",
    "sentense = 'I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .'\n",
    "ans = []\n",
    "for word in sentense.split(' '):\n",
    "    if len(word) <= 4:\n",
    "        ans.append(word)\n",
    "    else:\n",
    "        ans.append(word[0] + shuffle_str(word[1:-1])+word[-1])\n",
    "    \n",
    "print(ans)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ColabPractice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
